{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain v1.0 ê°€ì´ë“œ\n",
    "\n",
    "- **LangChain**ì€ LLM(Large Language Model) ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” í”„ë ˆì„ì›Œí¬\n",
    "\n",
    "- í•™ìŠµ ëª©í‘œ\n",
    "    - LangChain v1.0ì˜ í•µì‹¬ ê°œë…ê³¼ ì•„í‚¤í…ì²˜ ì´í•´\n",
    "    - ì—ì´ì „íŠ¸, ëª¨ë¸, ë„êµ¬, ë©”ì‹œì§€ ë“± í•µì‹¬ ì»´í¬ë„ŒíŠ¸ í™œìš©\n",
    "    - êµ¬ì¡°í™”ëœ ì¶œë ¥, ìŠ¤íŠ¸ë¦¬ë°, ë©”ëª¨ë¦¬ ê´€ë¦¬ ë“± ê³ ê¸‰ ê¸°ëŠ¥ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. LangChain ì†Œê°œ\n",
    "\n",
    "- í•µì‹¬ íŠ¹ì§•:\n",
    "\n",
    "    1. **ê°„í¸í•œ ì‹œì‘**\n",
    "        - 10ì¤„ ë¯¸ë§Œì˜ ì½”ë“œë¡œ ì—ì´ì „íŠ¸ êµ¬ì¶• ê°€ëŠ¥\n",
    "        - OpenAI, Anthropic, Google ë“± ì£¼ìš” LLM ì œê³µì—…ì²´ ì§€ì›\n",
    "\n",
    "    2. **ìœ ì—°í•œ í™•ì¥**\n",
    "        - ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜ë¡œ ì»´í¬ë„ŒíŠ¸ êµì²´ ìš©ì´\n",
    "        - ë‹¤ì–‘í•œ í†µí•©(700ê°œ ì´ìƒ) ì§€ì›\n",
    "\n",
    "    3. **í”„ë¡œë•ì…˜ ì¤€ë¹„**\n",
    "        - LangGraph ê¸°ë°˜ì˜ ì•ˆì •ì ì¸ ì‹¤í–‰ í™˜ê²½\n",
    "        - ìŠ¤íŠ¸ë¦¬ë°, ì§€ì†ì„±, Human-in-the-loop ì§€ì›\n",
    "\n",
    "- íƒ€ì„ë¼ì¸:\n",
    "    - **2022ë…„ 10ì›”**: LangChain v0.0.1 ì¶œì‹œ (ChatGPT ì¶œì‹œ 1ê°œì›” ì „)\n",
    "    - **2023ë…„ 1ì›”**: OpenAI Chat Completion API ì¶œì‹œ, ë©”ì‹œì§€ ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤ë¡œ ì „í™˜\n",
    "    - **2024ë…„ 6ì›”**: 700ê°œ ì´ìƒì˜ í†µí•© ì§€ì›, í†µí•© íŒ¨í‚¤ì§€ ë¶„ë¦¬\n",
    "    - **2024ë…„ 10ì›”**: LangGraphê°€ ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•ì˜ ì„ í˜¸ ë°©ì‹ìœ¼ë¡œ ìë¦¬ì¡ìŒ\n",
    "    - **2025ë…„ 1ì›”**: **LangChain v1.0 ì¶œì‹œ** - ì—ì´ì „íŠ¸ ì¤‘ì‹¬ì˜ ëŒ€ëŒ€ì  ê°œí¸\n",
    "\n",
    "- LangChainì˜ í•µì‹¬ ì‹ ë…:\n",
    "    - **LLMì€ ê°•ë ¥í•œ ìƒˆë¡œìš´ ê¸°ìˆ **\n",
    "    - **ì™¸ë¶€ ë°ì´í„°ì™€ ê²°í•©í•˜ë©´ ë”ìš± ê°•ë ¥í•´ì§**\n",
    "    - **ë¯¸ë˜ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì ì  ë” ì—ì´ì „í‹±(agentic)í•´ì§ˆ ê²ƒ**\n",
    "    - **ì•„ì§ ì´ˆê¸° ë‹¨ê³„ì´ë©°, í”„ë¡œë•ì…˜ê¸‰ ì—ì´ì „íŠ¸ êµ¬ì¶•ì€ ì—¬ì „íˆ ì–´ë ¤ì›€**\n",
    "\n",
    "- íŒ¨í‚¤ì§€ ì¬êµ¬ì„±\n",
    "\n",
    "    <div style=\"background-color: #fff3cd; padding: 15px; border-radius: 5px; margin: 10px 0;\">\n",
    "\n",
    "    âš ï¸ **ì¤‘ìš” ë³€ê²½ì‚¬í•­**\n",
    "\n",
    "    **`langchain` íŒ¨í‚¤ì§€** - í•µì‹¬ ê¸°ëŠ¥ë§Œ í¬í•¨:\n",
    "    - `langchain.agents`: ì—ì´ì „íŠ¸ ìƒì„± ë° ìƒíƒœ ê´€ë¦¬\n",
    "    - `langchain.messages`: ë©”ì‹œì§€ íƒ€ì…, ì½˜í…ì¸  ë¸”ë¡\n",
    "    - `langchain.tools`: ë„êµ¬ ë°ì½”ë ˆì´í„°, ë² ì´ìŠ¤ í´ë˜ìŠ¤\n",
    "    - `langchain.chat_models`: í†µí•© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    - `langchain.embeddings`: ì„ë² ë”© ëª¨ë¸\n",
    "\n",
    "    **`langchain-classic` íŒ¨í‚¤ì§€** - ë ˆê±°ì‹œ ê¸°ëŠ¥:\n",
    "    - ë ˆê±°ì‹œ ì²´ì¸ (`LLMChain`, `ConversationChain` ë“±)\n",
    "    - ë¦¬íŠ¸ë¦¬ë²„ (`MultiQueryRetriever` ë“±)\n",
    "    - ì¸ë±ì‹± API\n",
    "    - Hub ëª¨ë“ˆ\n",
    "    - ì»¤ë®¤ë‹ˆí‹° í†µí•© ì¬ìˆ˜ì¶œ\n",
    "\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3765fa5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "- ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "\n",
    "    ```bash\n",
    "    # pip ì‚¬ìš©\n",
    "    pip install -U langchain\n",
    "    # Python 3.10 ì´ìƒ í•„ìš”\n",
    "\n",
    "    # uv ì‚¬ìš© (ê¶Œì¥)\n",
    "    uv add langchain\n",
    "    ```\n",
    "\n",
    "- í†µí•© íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "\n",
    "    ```bash\n",
    "    # OpenAI í†µí•©\n",
    "    pip install -U langchain-openai\n",
    "\n",
    "    # Google í†µí•©\n",
    "    pip install -U langchain-google-genai\n",
    "    ```\n",
    "\n",
    "- API í‚¤ ì„¤ì •\n",
    "\n",
    "    ```bash\n",
    "    # .env íŒŒì¼ ìƒì„±\n",
    "    echo \"OPENAI_API_KEY=your-api-key-here\" > .env\n",
    "    echo \"GOOGLE_API_KEY=your-api-key-here\" >> .env\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# API í‚¤ í™•ì¸\n",
    "print(f\"OpenAI API í‚¤ ì„¤ì •ë¨: {bool(os.getenv('OPENAI_API_KEY'))}\")\n",
    "print(f\"Google API í‚¤ ì„¤ì •ë¨: {bool(os.getenv('GOOGLE_API_KEY'))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8990797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1.0ì˜ ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ ì¶”ìƒí™”\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"ì£¼ì–´ì§„ ë„ì‹œì˜ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "    return f\"{city}ëŠ” í•­ìƒ ë§‘ìŠµë‹ˆë‹¤!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤\",\n",
    ")\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ìƒŒí”„ë€ì‹œìŠ¤ì½”ì˜ ë‚ ì”¨ëŠ” ì–´ë•Œ?\"}]}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df293203",
   "metadata": {},
   "source": [
    "### [ì—°ìŠµë¬¸ì œ] í™˜ê²½ ì„¤ì •\n",
    "\n",
    "- **ë¬¸ì œ**: ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "    1. `langchain`ê³¼ `langchain-google-genai` íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.\n",
    "    2. `.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  Google API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\n",
    "    3. ìœ„ì˜ ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
    "    4. `get_weather` í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ì—¬ëŸ¬ ë„ì‹œì— ëŒ€í•´ ë‹¤ë¥¸ ë‚ ì”¨ë¥¼ ë°˜í™˜í•˜ë„ë¡ ë§Œë“œì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ê°œì„ ëœ ë‚ ì”¨ í•¨ìˆ˜\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"ì£¼ì–´ì§„ ë„ì‹œì˜ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "    weather_data = {\n",
    "        \"ì„œìš¸\": \"íë¦¬ê³  ë¹„ê°€ ì˜¬ ì˜ˆì •ì…ë‹ˆë‹¤. ê¸°ì˜¨ì€ 18ë„ì…ë‹ˆë‹¤.\",\n",
    "        \"ë¶€ì‚°\": \"ë§‘ê³  í™”ì°½í•©ë‹ˆë‹¤. ê¸°ì˜¨ì€ 22ë„ì…ë‹ˆë‹¤.\",\n",
    "        \"ì œì£¼\": \"êµ¬ë¦„ì´ ë§ê³  ë°”ëŒì´ ë¶‘ë‹ˆë‹¤. ê¸°ì˜¨ì€ 20ë„ì…ë‹ˆë‹¤.\",\n",
    "        \"ìƒŒí”„ë€ì‹œìŠ¤ì½”\": \"ì•ˆê°œê°€ ë¼ê³  ì„ ì„ í•©ë‹ˆë‹¤. ê¸°ì˜¨ì€ 15ë„ì…ë‹ˆë‹¤.\",\n",
    "    }\n",
    "    return weather_data.get(city, f\"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë‚ ì”¨ ì •ë³´ ì œê³µ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\",\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "cities = [\"ì„œìš¸\", \"ë¶€ì‚°\", \"ìƒŒí”„ë€ì‹œìŠ¤ì½”\", \"ë„ì¿„\"]\n",
    "for city in cities:\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": f\"{city}ì˜ ë‚ ì”¨ëŠ”?\"}]}\n",
    "    )\n",
    "    print(f\"\\n{city}: {result['messages'][-1].content}\")# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93521a47",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>âœ… ì˜ˆì‹œ ì •ë‹µ</summary>\n",
    "\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ê°œì„ ëœ ë‚ ì”¨ í•¨ìˆ˜\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"ì£¼ì–´ì§„ ë„ì‹œì˜ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "    weather_data = {\n",
    "        \"ì„œìš¸\": \"íë¦¬ê³  ë¹„ê°€ ì˜¬ ì˜ˆì •ì…ë‹ˆë‹¤. ê¸°ì˜¨ì€ 18ë„ì…ë‹ˆë‹¤.\",\n",
    "        \"ë¶€ì‚°\": \"ë§‘ê³  í™”ì°½í•©ë‹ˆë‹¤. ê¸°ì˜¨ì€ 22ë„ì…ë‹ˆë‹¤.\",\n",
    "        \"ì œì£¼\": \"êµ¬ë¦„ì´ ë§ê³  ë°”ëŒì´ ë¶‘ë‹ˆë‹¤. ê¸°ì˜¨ì€ 20ë„ì…ë‹ˆë‹¤.\",\n",
    "        \"ìƒŒí”„ë€ì‹œìŠ¤ì½”\": \"ì•ˆê°œê°€ ë¼ê³  ì„ ì„ í•©ë‹ˆë‹¤. ê¸°ì˜¨ì€ 15ë„ì…ë‹ˆë‹¤.\",\n",
    "    }\n",
    "    return weather_data.get(city, f\"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash-lite\",\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë‚ ì”¨ ì •ë³´ ì œê³µ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\",\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "cities = [\"ì„œìš¸\", \"ë¶€ì‚°\", \"ìƒŒí”„ë€ì‹œìŠ¤ì½”\", \"ë„ì¿„\"]\n",
    "for city in cities:\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": f\"{city}ì˜ ë‚ ì”¨ëŠ”?\"}]}\n",
    "    )\n",
    "    print(f\"\\n{city}: {result['messages'][-1].content}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46cc7b0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. í•µì‹¬ ì»´í¬ë„ŒíŠ¸\n",
    "\n",
    "### 3.1 ëª¨ë¸ (Models)\n",
    "\n",
    "LangChainì€ ë‹¤ì–‘í•œ LLMê³¼ í†µì‹ í•  ìˆ˜ ìˆëŠ” **í†µí•©ëœ ì¸í„°í˜ì´ìŠ¤**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0255e4",
   "metadata": {},
   "source": [
    "#### 3.1.1 ëª¨ë¸ ì´ˆê¸°í™” ë°©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca526b",
   "metadata": {},
   "source": [
    "- **ë°©ë²• 1: ëª¨ë¸ ì‹ë³„ì ë¬¸ìì—´ ì‚¬ìš©**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83707ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# ìë™ ì¶”ë¡  \n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-nano\",  # ìë™ìœ¼ë¡œ \"openai:gpt-4o-nano\"ë¡œ ì¶”ë¡ \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b0dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"ì•ˆë…•í•˜ì„¸ìš”.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f92c9",
   "metadata": {},
   "source": [
    "- **ë°©ë²• 2: init_chat_model ì‚¬ìš©**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b4d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# ëª…ì‹œì  ì´ˆê¸°í™”\n",
    "model = init_chat_model(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeeb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\"ì•ˆë…•í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a736bd",
   "metadata": {},
   "source": [
    "- **ë°©ë²• 3: ì œê³µì íŒ¨í‚¤ì§€ ì§ì ‘ ì‚¬ìš©**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# OpenAI\n",
    "openai_model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Google Gemini\n",
    "gemini_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4007602",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model.invoke(\"ì•ˆë…•í•˜ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea52311",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model.invoke(\"ì•ˆë…•í•˜ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0515dd",
   "metadata": {},
   "source": [
    "#### 3.1.2 ìŠ¤íŠ¸ë¦¬ë°\n",
    "\n",
    "ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹\n",
    "for chunk in model.stream(\"ì•µë¬´ìƒˆì˜ ê¹ƒí„¸ì´ í™”ë ¤í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"):\n",
    "    print(chunk.text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb07d82",
   "metadata": {},
   "source": [
    "#### 3.1.3 ë„êµ¬ í˜¸ì¶œ (Tool Calling)\n",
    "\n",
    "ëª¨ë¸ì´ ì™¸ë¶€ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ ì„¤ì •:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7abec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"íŠ¹ì • ìœ„ì¹˜ì˜ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "    return f\"{location}ëŠ” í™”ì°½í•©ë‹ˆë‹¤!\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "\n",
    "# ë„êµ¬ ë°”ì¸ë”©\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "# í˜¸ì¶œ\n",
    "response = model_with_tools.invoke(\"ìƒŒí”„ë€ì‹œìŠ¤ì½” ë‚ ì”¨ëŠ”?\")\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0f872",
   "metadata": {},
   "source": [
    "### [ì—°ìŠµë¬¸ì œ] ëª¨ë¸ í™œìš©\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "1. `gpt-4.1-mini` ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ì„¸ìš”.\n",
    "2. \"ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"ë¼ëŠ” ì§ˆë¬¸ì„ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.\n",
    "3. ì „ì²´ ì‘ë‹µì„ í•˜ë‚˜ì˜ `AIMessage` ê°ì²´ë¡œ ê²°í•©í•˜ì„¸ìš”.\n",
    "4. í† í° ì‚¬ìš©ëŸ‰ì„ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e5700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38038e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>âœ… ì˜ˆì‹œ ì •ë‹µ</summary>\n",
    "\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# 2. ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬\n",
    "print(\"ğŸ¤– AI ì‘ë‹µ:\\n\")\n",
    "full_message = None\n",
    "for chunk in model.stream(\"ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"):\n",
    "    print(chunk.text, end=\"\", flush=True)\n",
    "    # 3. AIMessage ê°ì²´ë¡œ ê²°í•©\n",
    "    full_message = chunk if full_message is None else full_message + chunk\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "\n",
    "# 4. í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥\n",
    "if full_message and full_message.usage_metadata:\n",
    "    usage = full_message.usage_metadata\n",
    "    print(f\"ğŸ“Š í† í° ì‚¬ìš©ëŸ‰:\")\n",
    "    print(f\"  ì…ë ¥ í† í°: {usage.get('input_tokens', 0)}\")\n",
    "    print(f\"  ì¶œë ¥ í† í°: {usage.get('output_tokens', 0)}\")\n",
    "    print(f\"  ì´ í† í°: {usage.get('total_tokens', 0)}\")\n",
    "else:\n",
    "    print(\"í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08e26e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.2 ë©”ì‹œì§€ (Messages)\n",
    "\n",
    "LangChainì€ ë‹¤ì–‘í•œ ë©”ì‹œì§€ íƒ€ì…ì„ ì œê³µí•˜ì—¬ ëŒ€í™”ë¥¼ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d6503",
   "metadata": {},
   "source": [
    "#### 3.2.1 HumanMessage (ì‚¬ìš©ì ë©”ì‹œì§€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfdfe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "\n",
    "# HumanMessage ìƒì„±\n",
    "human_message = HumanMessage(content=\"Gloryë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ëª¨ë¸ í˜¸ì¶œ\n",
    "response = model.invoke([human_message])\n",
    "print(f\"ë²ˆì—­: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd83b9c",
   "metadata": {},
   "source": [
    "#### 3.2.2 AIMessage (AI ì‘ë‹µ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI ì‘ë‹µì€ ìë™ìœ¼ë¡œ AIMessageë¡œ ë°˜í™˜ë¨\n",
    "response = model.invoke(\"ì•ˆë…•í•˜ì„¸ìš”!\")\n",
    "\n",
    "print(f\"íƒ€ì…: {type(response)}\")  # AIMessage\n",
    "print(f\"ë‚´ìš©: {response.content}\")\n",
    "print(f\"í† í° ì‚¬ìš©ëŸ‰: {response.usage_metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945759c",
   "metadata": {},
   "source": [
    "#### 3.2.3 SystemMessage (ì‹œìŠ¤í…œ ë©”ì‹œì§€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì—­í•  ì •ì˜\n",
    "system_msg = SystemMessage(\n",
    "    content=\"ë‹¹ì‹ ì€ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤.\"\n",
    ")\n",
    "human_msg = HumanMessage(content=\"Artificial Intelligence\")\n",
    "\n",
    "# ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ í˜¸ì¶œ\n",
    "messages = [system_msg, human_msg]\n",
    "response = model.invoke(messages)\n",
    "print(f\"ë²ˆì—­: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a98fa",
   "metadata": {},
   "source": [
    "#### 3.2.4 ToolMessage (ë„êµ¬ ì‹¤í–‰ ê²°ê³¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b169b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"íŠ¹ì • ìœ„ì¹˜ì˜ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "    return f\"{location}ëŠ” í™”ì°½í•©ë‹ˆë‹¤!\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "\n",
    "# ë„êµ¬ ë°”ì¸ë”©\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "# í˜¸ì¶œ\n",
    "ai_message = model_with_tools.invoke(\"ìƒŒí”„ë€ì‹œìŠ¤ì½” ë‚ ì”¨ëŠ”?\")\n",
    "\n",
    "# ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ ì¶œë ¥\n",
    "print(ai_message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293905ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ì¶œë ¥\n",
    "\n",
    "tool_message = get_weather.invoke(ai_message.tool_calls[0])\n",
    "\n",
    "tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf82182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€í™” ê³„ì†\n",
    "messages = [\n",
    "    HumanMessage(\"ìƒŒí”„ë€ì‹œìŠ¤ì½” ë‚ ì”¨ëŠ”?\"),\n",
    "    ai_message,\n",
    "    tool_message\n",
    "]\n",
    "final_response = model.invoke(messages)\n",
    "print(final_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e527ec86",
   "metadata": {},
   "source": [
    "### [ì—°ìŠµë¬¸ì œ] ë©”ì‹œì§€ í™œìš©\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ êµ¬í˜„í•˜ì„¸ìš”. (`gpt-4.1-nano` ëª¨ë¸ ì‚¬ìš©)\n",
    "\n",
    "1. ì‹œìŠ¤í…œ ë©”ì‹œì§€: \"ë‹¹ì‹ ì€ ì „ë¬¸ ìˆ˜í•™ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒë“¤ì—ê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "2. ì‚¬ìš©ìê°€ \"í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ê°€ ë­ì˜ˆìš”?\"ë¼ê³  ì§ˆë¬¸\n",
    "3. AIê°€ ì‘ë‹µ\n",
    "4. ì‚¬ìš©ìê°€ \"ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”\"ë¼ê³  ì¶”ê°€ ì§ˆë¬¸\n",
    "5. ì „ì²´ ëŒ€í™” ë‚´ì—­ì„ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df624d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a6c28",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>âœ… ì˜ˆì‹œ ì •ë‹µ</summary>\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "\n",
    "# ëŒ€í™” ì‹œì‘\n",
    "messages = [\n",
    "    SystemMessage(content=\"ë‹¹ì‹ ì€ ì „ë¬¸ ìˆ˜í•™ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒë“¤ì—ê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"),\n",
    "    HumanMessage(content=\"í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ê°€ ë­ì˜ˆìš”?\")\n",
    "]\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì‘ë‹µ\n",
    "response1 = model.invoke(messages)\n",
    "print(f\"ğŸ¤– ì„ ìƒë‹˜: {response1.content}\\n\")\n",
    "\n",
    "# ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€\n",
    "messages.append(response1)\n",
    "messages.append(HumanMessage(content=\"ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”\"))\n",
    "\n",
    "# ë‘ ë²ˆì§¸ ì‘ë‹µ\n",
    "response2 = model.invoke(messages)\n",
    "print(f\"ğŸ¤– ì„ ìƒë‹˜: {response2.content}\\n\")\n",
    "\n",
    "# ì „ì²´ ëŒ€í™” ë‚´ì—­ ì¶œë ¥\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“ ì „ì²´ ëŒ€í™” ë‚´ì—­:\")\n",
    "print(\"=\"*60)\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    role = msg.__class__.__name__\n",
    "    print(f\"\\n[{i}] {role}:\")\n",
    "    print(f\"    {msg.content[:100]}...\" if len(msg.content) > 100 else f\"    {msg.content}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab33433",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.3 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Prompt Templates)\n",
    "\n",
    "í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì€ ë™ì  í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### 3.3.1 ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9aceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# í…œí”Œë¦¿ ìƒì„±\n",
    "template = PromptTemplate.from_template(\"{topic}ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•´ì¤˜\")\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "prompt = template.invoke({\"topic\": \"ê³ ì–‘ì´\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82584871",
   "metadata": {},
   "source": [
    "#### 3.3.2 ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a6fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ì—¬ëŸ¬ ë©”ì‹œì§€ë¥¼ í¬í•¨í•˜ëŠ” í…œí”Œë¦¿\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤\"),\n",
    "    (\"user\", \"{subject}ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”\")\n",
    "])\n",
    "\n",
    "# ì‚¬ìš©\n",
    "prompt = template.invoke({\"subject\": \"ì–‘ìì—­í•™\"})\n",
    "print(prompt.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c3737",
   "metadata": {},
   "source": [
    "#### 3.3.3 ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# ëŒ€í™” ê¸°ë¡ì„ ì‚½ì…í•  ìˆ˜ ìˆëŠ” í…œí”Œë¦¿\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# ì‚¬ìš©\n",
    "prompt = template.invoke({\n",
    "    \"chat_history\": [\n",
    "        HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”!\"),\n",
    "    ],\n",
    "    \"input\": \"ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œìš”?\"\n",
    "})\n",
    "\n",
    "print(prompt.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db60d228",
   "metadata": {},
   "source": [
    "#### 3.3.4 ì²´ì¸ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì»´í¬ë„ŒíŠ¸ ì •ì˜\n",
    "prompt = PromptTemplate.from_template(\"ë„ì‹œ {city}ì˜ íŠ¹ì§•ì„ ì•Œë ¤ì£¼ì„¸ìš”\")\n",
    "model = ChatOpenAI(model='gpt-4.1-nano')\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„± (LCEL: LangChain Expression Language)\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = chain.invoke({\"city\": \"íŒŒë¦¬\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d597c2e3",
   "metadata": {},
   "source": [
    "### [ì—°ìŠµë¬¸ì œ] í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‹¤ìŠµ\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” ë ˆì‹œí”¼ ì¶”ì²œ ì‹œìŠ¤í…œì„ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "1. `ChatPromptTemplate`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ êµ¬ì¡°ì˜ í…œí”Œë¦¿ ìƒì„±:\n",
    "   - ì‹œìŠ¤í…œ ë©”ì‹œì§€: \"ë‹¹ì‹ ì€ ì „ë¬¸ ìš”ë¦¬ì‚¬ì…ë‹ˆë‹¤. ì¬ë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë ˆì‹œí”¼ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\"\n",
    "   - ì‚¬ìš©ì ì…ë ¥: \"{ingredients}ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\"\n",
    "2. í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ íŒŒì„œë¡œ ì´ì–´ì§€ëŠ” ì²´ì¸ êµ¬ì„±\n",
    "3. \"í† ë§ˆí† , ê³„ë€, ì¹˜ì¦ˆ\"ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4836ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da09a7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>âœ… ì˜ˆì‹œ ì •ë‹µ</summary>\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì „ë¬¸ ìš”ë¦¬ì‚¬ì…ë‹ˆë‹¤. ì¬ë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë ˆì‹œí”¼ë¥¼ ì¶”ì²œí•˜ê³ , ê°„ë‹¨í•œ ì¡°ë¦¬ ë°©ë²•ë„ ì•Œë ¤ì¤ë‹ˆë‹¤.\"),\n",
    "    (\"user\", \"{ingredients}ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”. ë ˆì‹œí”¼ì™€ ì¡°ë¦¬ ë°©ë²•ë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.\")\n",
    "])\n",
    "\n",
    "# ëª¨ë¸ê³¼ íŒŒì„œ\n",
    "model = ChatOpenAI(model='gpt-4.1-nano', temperature=0.7)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 2. ì²´ì¸ êµ¬ì„±\n",
    "recipe_chain = template | model | parser\n",
    "\n",
    "# 3. ì‹¤í–‰\n",
    "ingredients = \"í† ë§ˆí† , ê³„ë€, ì¹˜ì¦ˆ\"\n",
    "print(f\"ğŸ¥˜ ì¬ë£Œ: {ingredients}\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = recipe_chain.invoke({\"ingredients\": ingredients})\n",
    "print(result)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d4b62",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.4 ì¶œë ¥ íŒŒì„œ (Output Parsers)\n",
    "\n",
    "ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "#### 3.4.1 ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a38b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# ì²´ì¸ì— í†µí•©\n",
    "chain = prompt | model | parser\n",
    "result = chain.invoke({\"city\": \"ë„ì¿„\"})\n",
    "\n",
    "# ê²°ê³¼ëŠ” ë¬¸ìì—´\n",
    "print(type(result))  # <class 'str'>\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d819167",
   "metadata": {},
   "source": [
    "#### 3.4.2 êµ¬ì¡°í™”ëœ ì¶œë ¥\n",
    "\n",
    "- **Pydanticì„ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4307d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class CityInfo(BaseModel):\n",
    "    \"\"\"ë„ì‹œ ì •ë³´ ìŠ¤í‚¤ë§ˆ\"\"\"\n",
    "    name: str = Field(description=\"ë„ì‹œ ì´ë¦„\")\n",
    "    population: int = Field(description=\"ì¸êµ¬ ìˆ˜\")\n",
    "    famous_landmarks: List[str] = Field(description=\"ìœ ëª… ëœë“œë§ˆí¬\")\n",
    "\n",
    "# ëª¨ë¸ì— êµ¬ì¡° ë°”ì¸ë”©\n",
    "model_with_structure = model.with_structured_output(CityInfo)\n",
    "\n",
    "# í˜¸ì¶œ\n",
    "result = model_with_structure.invoke(\"íŒŒë¦¬ì— ëŒ€í•´ ì•Œë ¤ì¤˜\")\n",
    "print(type(result))  # <class 'CityInfo'>\n",
    "print(f\"ë„ì‹œ: {result.name}\")\n",
    "print(f\"ì¸êµ¬: {result.population:,}ëª…\")\n",
    "print(f\"ëœë“œë§ˆí¬: {', '.join(result.famous_landmarks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dcee7f",
   "metadata": {},
   "source": [
    "### [ì—°ìŠµë¬¸ì œ] ì¶œë ¥ íŒŒì„œ ì‹¤ìŠµ\n",
    "\n",
    "**ë¬¸ì œ**: ì˜í™” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì‹œìŠ¤í…œì„ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "1. Pydantic `BaseModel`ë¡œ ë‹¤ìŒ í•„ë“œë¥¼ ê°€ì§„ `MovieInfo` ìŠ¤í‚¤ë§ˆ ì •ì˜:\n",
    "   - `title`: ì˜í™” ì œëª© (str)\n",
    "   - `genre`: ì¥ë¥´ (str)\n",
    "   - `release_year`: ê°œë´‰ ì—°ë„ (int)\n",
    "   - `rating`: í‰ì  (float, 0-10 ì‚¬ì´)\n",
    "   - `summary`: ê°„ë‹¨í•œ ì¤„ê±°ë¦¬ (str)\n",
    "\n",
    "2. ëª¨ë¸ì— êµ¬ì¡°ë¥¼ ë°”ì¸ë”©í•˜ê³  \"ì¸ì…‰ì…˜ ì˜í™”ì— ëŒ€í•´ ì•Œë ¤ì¤˜\"ë¡œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c795397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a80da7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>âœ… ì˜ˆì‹œ ì •ë‹µ</summary>\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
    "class MovieInfo(BaseModel):\n",
    "    \"\"\"ì˜í™” ì •ë³´ ìŠ¤í‚¤ë§ˆ\"\"\"\n",
    "    title: str = Field(description=\"ì˜í™” ì œëª©\")\n",
    "    genre: str = Field(description=\"ì˜í™” ì¥ë¥´ (ì˜ˆ: SF, ì•¡ì…˜, ë“œë¼ë§ˆ)\")\n",
    "    release_year: int = Field(description=\"ê°œë´‰ ì—°ë„\")\n",
    "    rating: float = Field(description=\"í‰ì  (0-10 ì‚¬ì´)\", ge=0, le=10)\n",
    "    summary: str = Field(description=\"ê°„ë‹¨í•œ ì¤„ê±°ë¦¬ (2-3ë¬¸ì¥)\")\n",
    "\n",
    "# 2. ëª¨ë¸ ì´ˆê¸°í™” ë° êµ¬ì¡° ë°”ì¸ë”©\n",
    "model = ChatOpenAI(model='gpt-4.1-nano')\n",
    "structured_model = model.with_structured_output(MovieInfo)\n",
    "\n",
    "# 3. í…ŒìŠ¤íŠ¸\n",
    "result = structured_model.invoke(\"ì¸ì…‰ì…˜ ì˜í™”ì— ëŒ€í•´ ì•Œë ¤ì¤˜\")\n",
    "\n",
    "print(\"ğŸ¬ ì˜í™” ì •ë³´:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ì œëª©: {result.title}\")\n",
    "print(f\"ì¥ë¥´: {result.genre}\")\n",
    "print(f\"ê°œë´‰ì—°ë„: {result.release_year}\")\n",
    "print(f\"í‰ì : {result.rating}/10\")\n",
    "print(f\"\\nì¤„ê±°ë¦¬:\\n{result.summary}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa66880",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.5 ë„êµ¬ (Tools)\n",
    "\n",
    "ë„êµ¬ëŠ” ì—ì´ì „íŠ¸ê°€ ì™¸ë¶€ ê¸°ëŠ¥ì„ í˜¸ì¶œí•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n",
    "\n",
    "#### 3.5.1 ê¸°ë³¸ ë„êµ¬ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c09a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"ë‘ ìˆ«ìë¥¼ ë”í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"ë‘ ìˆ«ìë¥¼ ê³±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# ë„êµ¬ ì •ë³´ í™•ì¸\n",
    "print(f\"ë„êµ¬ ì´ë¦„: {add.name}\")\n",
    "print(f\"ë„êµ¬ ì„¤ëª…: {add.description}\")\n",
    "print(f\"ë„êµ¬ ì¸ì: {add.args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ffddf",
   "metadata": {},
   "source": [
    "#### 3.5.2 ë„êµ¬ì™€ ì—ì´ì „íŠ¸ í†µí•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfebe829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# ë„êµ¬ ëª©ë¡\n",
    "tools = [add, multiply]\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"ë‹¹ì‹ ì€ ìˆ˜í•™ ê³„ì‚°ì„ ë„ì™€ì£¼ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"15 ê³±í•˜ê¸° 7ì€ ì–¼ë§ˆì¸ê°€ìš”?\"}]\n",
    "})\n",
    "\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9f08f",
   "metadata": {},
   "source": [
    "### [ì—°ìŠµë¬¸ì œ] ë„êµ¬ í™œìš©\n",
    "\n",
    "**ë¬¸ì œ**: ê°„ë‹¨í•œ ê³„ì‚°ê¸° ì—ì´ì „íŠ¸ë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "1. ë‹¤ìŒ ë„êµ¬ë“¤ì„ ì •ì˜í•˜ì„¸ìš”:\n",
    "   - `add`: ë‘ ìˆ˜ë¥¼ ë”í•˜ê¸°\n",
    "   - `subtract`: ë‘ ìˆ˜ë¥¼ ë¹¼ê¸°\n",
    "   - `multiply`: ë‘ ìˆ˜ë¥¼ ê³±í•˜ê¸°\n",
    "   - `divide`: ë‘ ìˆ˜ë¥¼ ë‚˜ëˆ„ê¸° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)\n",
    "\n",
    "2. ì´ ë„êµ¬ë“¤ì„ ì‚¬ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "3. ë‹¤ìŒ ì§ˆë¬¸ë“¤ë¡œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”:\n",
    "   - \"25 ë”í•˜ê¸° 17ì€?\"\n",
    "   - \"100ì—ì„œ 37ì„ ë¹¼ë©´?\"\n",
    "   - \"12 ê³±í•˜ê¸° 8ì€?\"\n",
    "   - \"144ë¥¼ 12ë¡œ ë‚˜ëˆ„ë©´?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c08edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5c2d39",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>âœ… ì˜ˆì‹œ ì •ë‹µ</summary>\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# 1. ë„êµ¬ ì •ì˜\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"ë‘ ìˆ«ìë¥¼ ë”í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def subtract(a: float, b: float) -> float:\n",
    "    \"\"\"ì²« ë²ˆì§¸ ìˆ«ìì—ì„œ ë‘ ë²ˆì§¸ ìˆ«ìë¥¼ ëºë‹ˆë‹¤.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"ë‘ ìˆ«ìë¥¼ ê³±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a: float, b: float) -> str:\n",
    "    \"\"\"ì²« ë²ˆì§¸ ìˆ«ìë¥¼ ë‘ ë²ˆì§¸ ìˆ«ìë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\"\"\"\n",
    "    if b == 0:\n",
    "        return \"ì˜¤ë¥˜: 0ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    result = a / b\n",
    "    return f\"{result:.2f}\"\n",
    "\n",
    "# 2. ì—ì´ì „íŠ¸ ìƒì„±\n",
    "tools = [add, subtract, multiply, divide]\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ìˆ˜í•™ ê³„ì‚°ê¸° ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê³„ì‚° ìš”ì²­ì„ ì •í™•íˆ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "# 3. í…ŒìŠ¤íŠ¸\n",
    "test_questions = [\n",
    "    \"25 ë”í•˜ê¸° 17ì€?\",\n",
    "    \"100ì—ì„œ 37ì„ ë¹¼ë©´?\",\n",
    "    \"12 ê³±í•˜ê¸° 8ì€?\",\n",
    "    \"144ë¥¼ 12ë¡œ ë‚˜ëˆ„ë©´?\",\n",
    "    \"ë³µì¡í•œ ê³„ì‚°: (25 + 15) ê³±í•˜ê¸° 2ëŠ”?\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§® ê³„ì‚°ê¸° ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\\n\" + \"=\"*60)\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\nâ“ ì§ˆë¬¸: {question}\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}]\n",
    "    })\n",
    "    print(f\"âœ… ë‹µë³€: {result['messages'][-1].content}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4afab7d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ì—ì´ì „íŠ¸ êµ¬ì¶•\n",
    "\n",
    "- **ì—ì´ì „íŠ¸(Agent)** ëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œ\n",
    "\n",
    "    1. ëª©í‘œë¥¼ ì´í•´í•˜ê³  ê³„íš ìˆ˜ë¦½\n",
    "    2. í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰\n",
    "    3. ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ ê²°ì •\n",
    "    4. ëª©í‘œ ë‹¬ì„±ê¹Œì§€ ë°˜ë³µ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8787f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.1 create_agentë¡œ ì—ì´ì „íŠ¸ ìƒì„±\n",
    "\n",
    "#### 4.1.1 ê¸°ë³¸ ì—ì´ì „íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689641c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"ì£¼ì–´ì§„ ë„ì‹œì˜ ë‚ ì”¨ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "    return f\"{city}ëŠ” í™”ì°½í•©ë‹ˆë‹¤!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"ìƒŒí”„ë€ì‹œìŠ¤ì½” ë‚ ì”¨ëŠ”?\"}]\n",
    "})\n",
    "\n",
    "for msg in result['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ec5e6",
   "metadata": {},
   "source": [
    "#### 4.1.2 ë‹¤ì¤‘ ë„êµ¬ ì—ì´ì „íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80601bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return f\"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼: [ê°€ìƒì˜ ê²€ìƒ‰ ê²°ê³¼]\"\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"ìˆ˜í•™ í‘œí˜„ì‹ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"ê³„ì‚° ê²°ê³¼: {result}\"\n",
    "    except:\n",
    "        return \"ê³„ì‚° ì˜¤ë¥˜\"\n",
    "\n",
    "@tool\n",
    "def translate(text: str, target_lang: str = \"í•œêµ­ì–´\") -> str:\n",
    "    \"\"\"í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return f\"'{text}'ë¥¼ {target_lang}ë¡œ ë²ˆì—­: [ë²ˆì—­ ê²°ê³¼]\"\n",
    "\n",
    "# ë‹¤ì¤‘ ë„êµ¬ ì—ì´ì „íŠ¸\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    tools=[search_web, calculate, translate],\n",
    "    system_prompt=\"\"\"ë‹¹ì‹ ì€ ë‹¤ì¬ë‹¤ëŠ¥í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
    "    - search_web: ì •ë³´ ê²€ìƒ‰\n",
    "    - calculate: ê³„ì‚°\n",
    "    - translate: ë²ˆì—­\n",
    "    \n",
    "    ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.\"\"\"\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"25 * 18ì„ ê³„ì‚°í•˜ê³ , ê²°ê³¼ë¥¼ ì¼ë³¸ì–´ë¡œ ë²ˆì—­í•´ì¤˜\"}]\n",
    "})\n",
    "\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ecb9d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.2 êµ¬ì¡°í™”ëœ ì¶œë ¥ (Structured Output)\n",
    "\n",
    "ì—ì´ì „íŠ¸ê°€ íŠ¹ì • í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "#### 4.2.1 ToolStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"ì—°ë½ì²˜ ì •ë³´\"\"\"\n",
    "    name: str = Field(description=\"ì´ë¦„\")\n",
    "    email: str = Field(description=\"ì´ë©”ì¼\")\n",
    "    phone: str = Field(description=\"ì „í™”ë²ˆí˜¸\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    tools=[search_web],\n",
    "    response_format=ToolStrategy(ContactInfo)\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"ì—°ë½ì²˜ ì¶”ì¶œ: í™ê¸¸ë™, hong@example.com, 010-1234-5678\"}]\n",
    "})\n",
    "\n",
    "print(result[\"structured_response\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f83e35",
   "metadata": {},
   "source": [
    "#### 4.2.2 ProviderStrategy\n",
    "\n",
    "ì œê³µìì˜ ë„¤ì´í‹°ë¸Œ êµ¬ì¡°í™” ì¶œë ¥ì„ ì‚¬ìš©:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0200785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.structured_output import ProviderStrategy\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-mini\",  # ë„¤ì´í‹°ë¸Œ êµ¬ì¡°í™” ì¶œë ¥ ì§€ì› ëª¨ë¸\n",
    "    tools=[],\n",
    "    response_format=ProviderStrategy(ContactInfo)\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"ì—°ë½ì²˜ ì¶”ì¶œ: í™ê¸¸ë™, hong@example.com, 010-1234-5678\"}]\n",
    "})\n",
    "\n",
    "print(result[\"structured_response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f861bf3c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.3 ë©”ëª¨ë¦¬ì™€ ì»¨í…ìŠ¤íŠ¸\n",
    "\n",
    "#### 4.3.1 ëŒ€í™” ë©”ëª¨ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì €ì¥ì†Œ\n",
    "memory = MemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    tools=[],\n",
    "    checkpointer=memory\n",
    ")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ëŒ€í™”\n",
    "config = {\"configurable\": {\"thread_id\": \"user-123\"}}\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ë‚´ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì•¼\"}]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc727b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‘ ë²ˆì§¸ ëŒ€í™” (ê°™ì€ thread_id)\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\"}]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51827730",
   "metadata": {},
   "source": [
    "### [ì—°ìŠµë¬¸ì œ] ì—ì´ì „íŠ¸ êµ¬ì¶•\n",
    "\n",
    "**ë¬¸ì œ**: ë‹¤ìŒ ê¸°ëŠ¥ì„ ê°€ì§„ \"ê°œì¸ ë¹„ì„œ ì—ì´ì „íŠ¸\"ë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "1. **ë„êµ¬ë“¤**:\n",
    "   - `get_current_time()`: í˜„ì¬ ì‹œê°„ ë°˜í™˜\n",
    "   - `set_reminder(task: str, time: str)`: ë¦¬ë§ˆì¸ë” ì„¤ì •\n",
    "   - `search_contact(name: str)`: ì—°ë½ì²˜ ê²€ìƒ‰\n",
    "   - `send_email(to: str, subject: str, body: str)`: ì´ë©”ì¼ ë°œì†¡\n",
    "\n",
    "2. **êµ¬ì¡°í™”ëœ ì¶œë ¥**: \n",
    "   ```python\n",
    "   class AssistantResponse(BaseModel):\n",
    "       action_taken: str\n",
    "       result: str\n",
    "       next_suggestion: str\n",
    "   ```\n",
    "\n",
    "3. **í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:\n",
    "   - \"í˜„ì¬ ì‹œê°„ ì•Œë ¤ì¤˜\"\n",
    "   - \"ë‚´ì¼ ì˜¤ì „ 10ì‹œì— íšŒì˜ ë¦¬ë§ˆì¸ë” ì„¤ì •í•´ì¤˜\"\n",
    "   - \"í™ê¸¸ë™ ì—°ë½ì²˜ ì°¾ì•„ì¤˜\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a684119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "# 1. ë„êµ¬ ì •ì˜\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"í˜„ì¬ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„\")\n",
    "\n",
    "@tool\n",
    "def set_reminder(task: str, time: str) -> str:\n",
    "    \"\"\"ë¦¬ë§ˆì¸ë”ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return f\"âœ… ë¦¬ë§ˆì¸ë” ì„¤ì •ë¨: '{task}' - {time}\"\n",
    "\n",
    "@tool\n",
    "def search_contact(name: str) -> str:\n",
    "    \"\"\"ì—°ë½ì²˜ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    # ê°€ìƒì˜ ì—°ë½ì²˜ ë°ì´í„°ë² ì´ìŠ¤\n",
    "    contacts = {\n",
    "        \"í™ê¸¸ë™\": {\"phone\": \"010-1234-5678\", \"email\": \"hong@example.com\"},\n",
    "        \"ê¹€ì² ìˆ˜\": {\"phone\": \"010-9876-5432\", \"email\": \"kim@example.com\"},\n",
    "    }\n",
    "    \n",
    "    if name in contacts:\n",
    "        contact = contacts[name]\n",
    "        return f\"ğŸ“ {name}: {contact['phone']}, {contact['email']}\"\n",
    "    return f\"âŒ '{name}' ì—°ë½ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"ì´ë©”ì¼ì„ ë°œì†¡í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return f\"ğŸ“§ ì´ë©”ì¼ ë°œì†¡ë¨:\\n  ìˆ˜ì‹ : {to}\\n  ì œëª©: {subject}\\n  ë‚´ìš©: {body[:50]}...\"\n",
    "\n",
    "# 2. êµ¬ì¡°í™”ëœ ì¶œë ¥ ìŠ¤í‚¤ë§ˆ\n",
    "class AssistantResponse(BaseModel):\n",
    "    \"\"\"ë¹„ì„œ ì‘ë‹µ í˜•ì‹\"\"\"\n",
    "    action_taken: str = Field(description=\"ìˆ˜í–‰í•œ ì‘ì—…\")\n",
    "    result: str = Field(description=\"ì‘ì—… ê²°ê³¼\")\n",
    "    next_suggestion: str = Field(description=\"ë‹¤ìŒ ì œì•ˆì‚¬í•­\")\n",
    "\n",
    "# 3. ì—ì´ì „íŠ¸ ìƒì„±\n",
    "tools = [get_current_time, set_reminder, search_contact, send_email]\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"\"\"ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ëŠ¥ë ¥ìˆëŠ” ê°œì¸ ë¹„ì„œì…ë‹ˆë‹¤.\n",
    "    \n",
    "    ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì •í™•íˆ ì´í•´í•˜ê³ , ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—…ë¬´ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.\n",
    "    í•­ìƒ ì •ì¤‘í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì‘ëŒ€í•˜ë©°, ì¶”ê°€ë¡œ ë„ì›€ì´ ë  ë§Œí•œ ì œì•ˆì„ í•´ì£¼ì„¸ìš”.\"\"\",\n",
    "    response_format=ToolStrategy(AssistantResponse)\n",
    ")\n",
    "\n",
    "# 4. í…ŒìŠ¤íŠ¸\n",
    "test_scenarios = [\n",
    "    \"í˜„ì¬ ì‹œê°„ ì•Œë ¤ì¤˜\",\n",
    "    \"ë‚´ì¼ ì˜¤ì „ 10ì‹œì— í”„ë¡œì íŠ¸ íšŒì˜ ë¦¬ë§ˆì¸ë” ì„¤ì •í•´ì¤˜\",\n",
    "    \"í™ê¸¸ë™ ì—°ë½ì²˜ ì°¾ì•„ì¤˜\",\n",
    "    \"ê¹€ì² ìˆ˜ì—ê²Œ 'ì•ˆë¶€ ì¸ì‚¬'ë¼ëŠ” ì œëª©ìœ¼ë¡œ 'ì˜ ì§€ë‚´ì‹œì£ ?'ë¼ëŠ” ë‚´ìš©ì˜ ì´ë©”ì¼ ë³´ë‚´ì¤˜\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ¤– ê°œì¸ ë¹„ì„œ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    print(f\"ğŸ“ ìš”ì²­: {scenario}\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": scenario}]\n",
    "    })\n",
    "    \n",
    "    response = result[\"structured_response\"]\n",
    "    print(f\"  ì‘ì—…: {response.action_taken}\")\n",
    "    print(f\"  ê²°ê³¼: {response.result}\")\n",
    "    print(f\"  ì œì•ˆ: {response.next_suggestion}\")\n",
    "    print(\"-\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a0611",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>âœ… ì˜ˆì‹œ ì •ë‹µ</summary>\n",
    "\n",
    "```python\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "# 1. ë„êµ¬ ì •ì˜\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"í˜„ì¬ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„\")\n",
    "\n",
    "@tool\n",
    "def set_reminder(task: str, time: str) -> str:\n",
    "    \"\"\"ë¦¬ë§ˆì¸ë”ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return f\"âœ… ë¦¬ë§ˆì¸ë” ì„¤ì •ë¨: '{task}' - {time}\"\n",
    "\n",
    "@tool\n",
    "def search_contact(name: str) -> str:\n",
    "    \"\"\"ì—°ë½ì²˜ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    # ê°€ìƒì˜ ì—°ë½ì²˜ ë°ì´í„°ë² ì´ìŠ¤\n",
    "    contacts = {\n",
    "        \"í™ê¸¸ë™\": {\"phone\": \"010-1234-5678\", \"email\": \"hong@example.com\"},\n",
    "        \"ê¹€ì² ìˆ˜\": {\"phone\": \"010-9876-5432\", \"email\": \"kim@example.com\"},\n",
    "    }\n",
    "    \n",
    "    if name in contacts:\n",
    "        contact = contacts[name]\n",
    "        return f\"ğŸ“ {name}: {contact['phone']}, {contact['email']}\"\n",
    "    return f\"âŒ '{name}' ì—°ë½ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"ì´ë©”ì¼ì„ ë°œì†¡í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return f\"ğŸ“§ ì´ë©”ì¼ ë°œì†¡ë¨:\\n  ìˆ˜ì‹ : {to}\\n  ì œëª©: {subject}\\n  ë‚´ìš©: {body[:50]}...\"\n",
    "\n",
    "# 2. êµ¬ì¡°í™”ëœ ì¶œë ¥ ìŠ¤í‚¤ë§ˆ\n",
    "class AssistantResponse(BaseModel):\n",
    "    \"\"\"ë¹„ì„œ ì‘ë‹µ í˜•ì‹\"\"\"\n",
    "    action_taken: str = Field(description=\"ìˆ˜í–‰í•œ ì‘ì—…\")\n",
    "    result: str = Field(description=\"ì‘ì—… ê²°ê³¼\")\n",
    "    next_suggestion: str = Field(description=\"ë‹¤ìŒ ì œì•ˆì‚¬í•­\")\n",
    "\n",
    "# 3. ì—ì´ì „íŠ¸ ìƒì„±\n",
    "tools = [get_current_time, set_reminder, search_contact, send_email]\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"\"\"ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ëŠ¥ë ¥ìˆëŠ” ê°œì¸ ë¹„ì„œì…ë‹ˆë‹¤.\n",
    "    \n",
    "    ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì •í™•íˆ ì´í•´í•˜ê³ , ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—…ë¬´ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.\n",
    "    í•­ìƒ ì •ì¤‘í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì‘ëŒ€í•˜ë©°, ì¶”ê°€ë¡œ ë„ì›€ì´ ë  ë§Œí•œ ì œì•ˆì„ í•´ì£¼ì„¸ìš”.\"\"\",\n",
    "    response_format=ToolStrategy(AssistantResponse)\n",
    ")\n",
    "\n",
    "# 4. í…ŒìŠ¤íŠ¸\n",
    "test_scenarios = [\n",
    "    \"í˜„ì¬ ì‹œê°„ ì•Œë ¤ì¤˜\",\n",
    "    \"ë‚´ì¼ ì˜¤ì „ 10ì‹œì— í”„ë¡œì íŠ¸ íšŒì˜ ë¦¬ë§ˆì¸ë” ì„¤ì •í•´ì¤˜\",\n",
    "    \"í™ê¸¸ë™ ì—°ë½ì²˜ ì°¾ì•„ì¤˜\",\n",
    "    \"ê¹€ì² ìˆ˜ì—ê²Œ 'ì•ˆë¶€ ì¸ì‚¬'ë¼ëŠ” ì œëª©ìœ¼ë¡œ 'ì˜ ì§€ë‚´ì‹œì£ ?'ë¼ëŠ” ë‚´ìš©ì˜ ì´ë©”ì¼ ë³´ë‚´ì¤˜\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ¤– ê°œì¸ ë¹„ì„œ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    print(f\"ğŸ“ ìš”ì²­: {scenario}\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": scenario}]\n",
    "    })\n",
    "    \n",
    "    response = result[\"structured_response\"]\n",
    "    print(f\"  ì‘ì—…: {response.action_taken}\")\n",
    "    print(f\"  ê²°ê³¼: {response.result}\")\n",
    "    print(f\"  ì œì•ˆ: {response.next_suggestion}\")\n",
    "    print(\"-\"*70 + \"\\n\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}