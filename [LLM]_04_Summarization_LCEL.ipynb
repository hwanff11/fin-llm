{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê¸ˆìœµ ë¬¸ì„œ ìš”ì•½ (Financial Document Summarization)\n",
    "\n",
    "LangChainì˜ **LCEL**ì„ ì‚¬ìš©í•˜ì—¬ ê¸ˆìœµ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "- LCEL (LangChain Expression Language) ì´í•´\n",
    "    - **ëª©ì **: ê²°ì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì²´ì¸ êµ¬ì„±\n",
    "    - **íŠ¹ì§•**: \n",
    "        - íŒŒì´í”„(`|`) ì—°ì‚°ìë¡œ ì»´í¬ë„ŒíŠ¸ ì—°ê²°\n",
    "        - ëª…í™•í•œ ë°ì´í„° íë¦„\n",
    "        - ë¹ ë¥¸ ì‹¤í–‰ ì†ë„\n",
    "        - ë””ë²„ê¹… ìš©ì´\n",
    "\n",
    "- LCEL ë°©ì‹ì˜ ìš”ì•½ ì²´ì¸ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì‹œ ë¬¸ì„œ ë¡œë“œ\n",
    "loader = PyPDFLoader(\"data/ê¸ˆìœµì•ˆì •ë³´ê³ ì„œ(2025ë…„ 6ì›”).pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"í˜ì´ì§€ ìˆ˜: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32  í˜ì´ì§€ ë‚´ìš©\n",
    "print(docs[31].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 í˜ì´ì§€ ë©”íƒ€ë°ì´í„°\n",
    "print(docs[31].metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ê¸°ë³¸ ìš”ì•½ ì²´ì¸ (Simple Chain)\n",
    "\n",
    "- **ëª©ì **: ê°„ë‹¨í•˜ê³  ë¹ ë¥¸ ìš”ì•½\n",
    "\n",
    "- LCEL ê¸°ë³¸ êµ¬ì¡°\n",
    "\n",
    "    - íŒŒì´í”„ ì—°ì‚°ì(`|`): ì»´í¬ë„ŒíŠ¸ ì—°ê²°\n",
    "    - ì»´í¬ë„ŒíŠ¸: LLM, Tool, Prompt, OutputParser ë“±\n",
    "\n",
    "        ```python\n",
    "        # ê¸°ë³¸ íŒ¨í„´\n",
    "        chain = prompt | model | output_parser\n",
    "\n",
    "        # ìš”ì•½ ì²´ì¸ ì˜ˆì‹œ\n",
    "        basic_summary_chain = (\n",
    "            basic_summary_prompt      # 1. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "            | llm                     # 2. ì–¸ì–´ ëª¨ë¸\n",
    "            | StrOutputParser()       # 3. ì¶œë ¥ íŒŒì„œ\n",
    "        )\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ê¸°ë³¸ ìš”ì•½ ì²´ì¸ êµ¬ì„±\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "basic_summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ê¸ˆìœµ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"),\n",
    "    (\"human\", \"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”:\\n\\n{text}\")\n",
    "])\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "\n",
    "# ì¶œë ¥ íŒŒì„œ\n",
    "ouput_parser = StrOutputParser()\n",
    "\n",
    "# ê¸°ë³¸ ìš”ì•½ ì²´ì¸\n",
    "basic_summary_chain = basic_summary_prompt | llm | ouput_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì‹œ ë¬¸ì„œ ìš”ì•½ (32 í˜ì´ì§€)\n",
    "\n",
    "summary = basic_summary_chain.invoke({\"text\": docs[31].page_content})\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**íŠ¹ì§•**:\n",
    "- ë‹¨ì¼ ì…ë ¥ â†’ ë‹¨ì¼ ì¶œë ¥\n",
    "- ê°€ì¥ ë¹ ë¥¸ ì‹¤í–‰ ì†ë„\n",
    "- ëª…í™•í•œ ëª©ì \n",
    "\n",
    "**ì‚¬ìš© ì‹œì **:\n",
    "- ë¹ ë¥¸ ê°œìš”ê°€ í•„ìš”í•  ë•Œ\n",
    "- ë‹¨ìˆœí•œ ìš”ì•½ì´ ì¶©ë¶„í•  ë•Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. êµ¬ì¡°í™”ëœ ìš”ì•½ ì²´ì¸ (Structured Chain)\n",
    "\n",
    "- **ëª©ì **: ì¼ê´€ëœ í˜•ì‹ì˜ ìƒì„¸ ë¶„ì„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë‹¹ì‹ ì€ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”:\n",
    "    \n",
    "    [í•µì‹¬ ìš”ì•½]\n",
    "    [ì¬ë¬´ ì§€í‘œ]\n",
    "    [ì£¼ìš” ë™ì¸]\n",
    "    [ë¦¬ìŠ¤í¬ ìš”ì¸]\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "structured_summary_chain = structured_summary_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì‹œ ë¬¸ì„œ ìš”ì•½ (32 í˜ì´ì§€)\n",
    "\n",
    "summary = structured_summary_chain.invoke({\"text\": docs[31].page_content})\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**íŠ¹ì§•**:\n",
    "- í”„ë¡¬í”„íŠ¸ì—ì„œ êµ¬ì¡° ì •ì˜\n",
    "- ì¼ê´€ëœ ì¶œë ¥ í˜•ì‹\n",
    "- ê°€ë…ì„± ë†’ì€ ê²°ê³¼\n",
    "\n",
    "**ì‚¬ìš© ì‹œì **:\n",
    "- ë³´ê³ ì„œ ì‘ì„± ì‹œ\n",
    "- íŒ€ ê°„ ì¼ê´€ëœ í¬ë§· í•„ìš” ì‹œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë³‘ë ¬ ì²˜ë¦¬ ì²´ì¸ (Parallel Chain)\n",
    "\n",
    "- **ëª©ì **: ì—¬ëŸ¬ ê´€ì ì„ ë™ì‹œì— ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì¬ë¬´ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¬ë¬´ì§€í‘œë¥¼ ë¶„ì„í•˜ì„¸ìš”.\"),\n",
    "    (\"user\", \"{data}\")\n",
    "])\n",
    "\n",
    "\n",
    "risk_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ë¦¬ìŠ¤í¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ìœ„í—˜ìš”ì¸ì„ ë¶„ì„í•˜ì„¸ìš”.\"),\n",
    "    (\"user\", \"{data}\")\n",
    "])\n",
    "\n",
    "\n",
    "opportunity_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì „ëµê¸°íšŒ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê¸°íšŒ ìš”ì¸ì„ ì°¾ìœ¼ì„¸ìš”.\"),\n",
    "    (\"user\", \"{data}\")\n",
    "])\n",
    "\n",
    "\n",
    "parallel_chain = RunnableParallel(\n",
    "    financial_analysis=financial_prompt | llm | StrOutputParser(),\n",
    "    risk_analysis=risk_prompt | llm | StrOutputParser(),\n",
    "    opportunity_analysis=opportunity_prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "summary = parallel_chain.invoke({\n",
    "    \"data\": docs[31].page_content\n",
    "})  \n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary['financial_analysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary['risk_analysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary['opportunity_analysis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë‹¤ë‹¨ê³„ ì²˜ë¦¬ ì²´ì¸ (Multi-stage Chain)\n",
    "\n",
    "- **ëª©ì **: ì´ì „ ê²°ê³¼ë¥¼ ë‹¤ìŒ ë‹¨ê³„ì—ì„œ í™œìš©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ê¸ˆìœµ ë¶„ì„ ê´€ì ì—ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "detailed_analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ê¸ˆìœµ ë³´ê³ ì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ë¥¼ í† ëŒ€ë¡œ ìƒì„¸í•œ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\"),\n",
    "    (\"human\", \"{summary}\")\n",
    "])\n",
    "\n",
    "multi_stage_chain = (\n",
    "    # 1ë‹¨ê³„: ì´ˆê¸° ìš”ì•½\n",
    "    {\"summary\": initial_summary_prompt | llm | StrOutputParser()}\n",
    "    # 2ë‹¨ê³„: ìš”ì•½ ê²°ê³¼ë¥¼ ì‚¬ìš©í•œ ìƒì„¸ ë¶„ì„\n",
    "    | RunnablePassthrough.assign(\n",
    "        analysis=lambda x: (detailed_analysis_prompt | llm | StrOutputParser()).invoke(x)\n",
    "    )\n",
    ")\n",
    "\n",
    "detailed_report = multi_stage_chain.invoke({\"text\": docs[31].page_content})\n",
    "print(detailed_report)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(detailed_report['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(detailed_report['analysis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ì‹¤ìŠµ ë¬¸ì œ (Exercises)\n",
    "\n",
    "### ë¬¸ì œ 1: í•µì‹¬ ìš”ì•½ (Bullet Points)\n",
    "\n",
    "ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ **3-5ê°œì˜ í•µì‹¬ ìš”ì•½(Bullet Points)** ë¡œ ì •ë¦¬í•˜ëŠ” ì²´ì¸ì„ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "1. `ChatPromptTemplate`ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "2. `ChatOpenAI` ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "3. `StrOutputParser`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ìì—´ë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "4. `docs[31].page_content`ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "ex1_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 3-5ê°œì˜ í•µì‹¬ ìš”ì•½(Bullet Points)ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "ex1_chain = ex1_prompt | llm | StrOutputParser()\n",
    "\n",
    "print(ex1_chain.invoke({\"text\": docs[31].page_content}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ ì˜ˆì‹œ ì •ë‹µ</summary>\n",
    "\n",
    "```python\n",
    "ex1_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 3-5ê°œì˜ í•µì‹¬ ìš”ì•½(Bullet Points)ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "ex1_chain = ex1_prompt | llm | StrOutputParser()\n",
    "\n",
    "print(ex1_chain.invoke({\"text\": docs[31].page_content}))\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 2: ê¸ì •/ë¶€ì • ì‹ í˜¸ ë¶„ì„ (Parallel Chain)\n",
    "\n",
    "ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ **ê¸ì •ì  ì‹ í˜¸(Positive Signals)**ì™€ **ë¶€ì •ì  ì‹ í˜¸(Negative Signals)**ë¥¼ ë™ì‹œì— ë¶„ì„í•˜ëŠ” ë³‘ë ¬ ì²´ì¸ì„ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "1. `positive_prompt`ì™€ `negative_prompt`ë¥¼ ê°ê° ì‘ì„±í•˜ì„¸ìš”.\n",
    "2. `RunnableParallel`ì„ ì‚¬ìš©í•˜ì—¬ ë‘ ë¶„ì„ì„ ë™ì‹œì— ì‹¤í–‰í•˜ì„¸ìš”.\n",
    "3. ê²°ê³¼ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì¶œë ¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤ (`positive`, `negative` í‚¤ ì‚¬ìš©)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ ì˜ˆì‹œ ì •ë‹µ</summary>\n",
    "\n",
    "```python\n",
    "# ì •ë‹µ ì˜ˆì‹œ\n",
    "positive_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"í…ìŠ¤íŠ¸ì—ì„œ ê¸ì •ì ì¸ ì‹œì¥ ì‹ í˜¸ë‚˜ ì§€í‘œë§Œ ì¶”ì¶œí•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "negative_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"í…ìŠ¤íŠ¸ì—ì„œ ë¶€ì •ì ì¸ ì‹œì¥ ì‹ í˜¸ë‚˜ ìœ„í—˜ ìš”ì¸ë§Œ ì¶”ì¶œí•˜ì—¬ ìš”ì•½í•˜ì„¸ìš”.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "ex2_chain = RunnableParallel(\n",
    "    positive=positive_prompt | llm | StrOutputParser(),\n",
    "    negative=negative_prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = ex2_chain.invoke({\"text\": docs[31].page_content})\n",
    "print(\"=== ê¸ì •ì  ì‹ í˜¸ ===\\n\", result['positive'])\n",
    "print(\"\\n=== ë¶€ì •ì  ì‹ í˜¸ ===\\n\", result['negative'])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 3: íˆ¬ì ì œì•ˆ ë©”ì¼ ì‘ì„± (Multi-stage Chain)\n",
    "\n",
    "ë¬¸ì„œë¥¼ ìš”ì•½í•œ í›„, ê·¸ ìš”ì•½ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì—ê²Œ ë³´ë‚¼ **íˆ¬ì ì œì•ˆ ì´ë©”ì¼**ì„ ì‘ì„±í•˜ëŠ” ì²´ì¸ì„ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­**:\n",
    "1. **1ë‹¨ê³„**: í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤ (ê¸°ì¡´ `basic_summary_chain` í™œìš© ê°€ëŠ¥).\n",
    "2. **2ë‹¨ê³„**: ìš”ì•½ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ \"íˆ¬ì ì œì•ˆ ì´ë©”ì¼\"ì„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "3. `RunnablePassthrough` ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ê³„ë¥¼ ì—°ê²°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ ì˜ˆì‹œ ì •ë‹µ</summary>\n",
    "\n",
    "```python\n",
    "email_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ íˆ¬ì ìë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìš”ì•½ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì—ê²Œ íˆ¬ì ì „ëµì„ ì œì•ˆí•˜ëŠ” ì •ì¤‘í•œ ì´ë©”ì¼ì„ ì‘ì„±í•˜ì„¸ìš”.\"),\n",
    "    (\"human\", \"ìš”ì•½ ë‚´ìš©:\\n{summary}\")\n",
    "])\n",
    "\n",
    "ex3_chain = (\n",
    "    {\"summary\": basic_summary_chain}\n",
    "    | email_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(ex3_chain.invoke({\"text\": docs[31].page_content}))\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}