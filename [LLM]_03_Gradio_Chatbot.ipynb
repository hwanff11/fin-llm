{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2631b5",
   "metadata": {},
   "source": [
    "#  Gradio 챗봇 구현 (간단한 QA 애플리케이션)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd9328",
   "metadata": {
    "id": "8bfd9328"
   },
   "source": [
    "##  환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac3ddb",
   "metadata": {
    "id": "15ac3ddb"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b8eee",
   "metadata": {
    "id": "129b8eee"
   },
   "source": [
    "## Simple QA Chain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722db67",
   "metadata": {
    "id": "3722db67"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 파이썬(Python) 코드 작성을 도와주는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# LLM 모델 정의\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\", \n",
    "    temperature=0.3, \n",
    "    )\n",
    "\n",
    "# 프롬프트 템플릿 + LLM 모델 + 출력파서를 연결하여 체인 생성\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# 체인 실행\n",
    "response = chain.invoke({\n",
    "    \"user_input\": \"파이썬에서 리스트를 정렬하는 방법은 무엇인가요?\"\n",
    "})\n",
    "\n",
    "# AI의 응답 텍스트를 출력 \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87eef4",
   "metadata": {
    "id": "9e87eef4"
   },
   "outputs": [],
   "source": [
    "# 마크다운 출력\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a59f9",
   "metadata": {},
   "source": [
    "## Gradio ChatInterface  \n",
    "- 설치: pip install gradio --upgrade 또는 uv add gradio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65443d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# 챗봇 함수 정의\n",
    "def chat_function(message, history):\n",
    "\n",
    "    # 프롬프트 템플릿 정의\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"당신은 파이썬(Python) 코드 작성을 도와주는 AI 어시스턴트입니다.\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ])\n",
    "\n",
    "    # LLM 모델 정의\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4.1-nano\", \n",
    "        temperature=0.3, \n",
    "        )\n",
    "\n",
    "    # 프롬프트 템플릿 + LLM 모델 + 출력파서를 연결하여 체인 생성\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # 체인 실행\n",
    "    response = chain.invoke({\n",
    "        \"user_input\": message\n",
    "    })\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# 챗봇 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_function,         # 실행할 함수\n",
    "    analytics_enabled=False,  # 사용 정보 제공 여부\n",
    ")\n",
    "\n",
    "# 챗봇 인터페이스 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인터페이스 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0408b4",
   "metadata": {},
   "source": [
    "### 채팅 히스토리 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# 챗봇 함수 정의\n",
    "def chat_function(message, history):\n",
    "\n",
    "    # 프롬프트 템플릿 정의\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"당신은 파이썬(Python) 코드 작성을 도와주는 AI 어시스턴트입니다.\"),\n",
    "        MessagesPlaceholder(\"chat_history\"),        \n",
    "        (\"human\", \"{user_input}\")\n",
    "    ])\n",
    "\n",
    "    # LLM 모델 정의\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4.1-nano\", \n",
    "        temperature=0.3, \n",
    "        )\n",
    "\n",
    "    # 프롬프트 템플릿 + LLM 모델 + 출력파서를 연결하여 체인 생성\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # 체인 실행\n",
    "    response = chain.invoke({\n",
    "        \"user_input\": message,\n",
    "        \"chat_history\": history\n",
    "    })\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# 챗봇 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_function,         # 실행할 함수\n",
    "    analytics_enabled=False,  # 사용 정보 제공 여부\n",
    ")\n",
    "\n",
    "# 챗봇 인터페이스 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f92bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d46b8",
   "metadata": {},
   "source": [
    "# [실습 프로젝트]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b260a",
   "metadata": {},
   "source": [
    "- **다음과 같은 요구사항을 Gradio ChatInterface로 구현합니다**\n",
    "\n",
    "- 주제: 맞춤형 여행 일정 계획 어시스턴트\n",
    "- 기능: \n",
    "   - OpenAI API와 LangChain을 활용하여 사용자의 선호도에 맞는 여행 일정을 생성\n",
    "   - 채팅 히스토리 사용하여 답변 생성\n",
    "   - Gradio 인터페이스를 통해 사용자와 대화형으로 상호작용\n",
    "\n",
    "- 주요 포인트:\n",
    "\n",
    "   1. **모델 매개변수 최적화**\n",
    "      - temperature=0.7: 적당한 창의성을 유지하면서 일관된 응답 생성\n",
    "      - top_p=0.9: 높은 확률의 토큰만 선택하여 응답의 품질 향상\n",
    "      - presence_penalty와 frequency_penalty: 반복적인 응답을 줄이고 다양한 제안 생성\n",
    "\n",
    "   2. **시스템 프롬프트 설계**\n",
    "      - 여행 플래너로서의 역할과 응답 가이드라인을 명확히 정의\n",
    "      - 구체적인 정보를 포함하도록 지시\n",
    "      - 한국어 응답 명시\n",
    "\n",
    "   3. **메모리 관리**\n",
    "      - Gradio 메모리 기능을 사용하여 대화 컨텍스트 유지\n",
    "      - 이전 대화 내용을 바탕으로 연속성 있는 응답 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio 인터페이스 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77315adc",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>✅ 예시 정답</summary>\n",
    "\n",
    "```python\n",
    "# 필수 라이브러리 임포트\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# 메시지 플레이스홀더가 있는 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"여행 일정을 계획해주는 AI 어시스턴트입니다. 사용자의 선호도에 맞는 여행 일정을 계획해주세요.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# LLM 모델 정의\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\", \n",
    "    temperature=0.7, \n",
    "    top_p=0.9,\n",
    "    presence_penalty=0.3,\n",
    "    frequency_penalty=0.3,\n",
    "    )\n",
    "\n",
    "# 프롬프트 템플릿 + LLM 모델 + 출력파서를 연결하여 체인 생성\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# 사용자 메시지를 처리하고 AI 응답을 생성하는 함수 (chat_history 사용)\n",
    "def answer_invoke(message, history):\n",
    "    response = chain.invoke({\n",
    "        \"chat_history\": history,\n",
    "        \"user_input\": message\n",
    "    })\n",
    "    return response\n",
    "\n",
    "# Gradio ChatInterface 객체 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,         # 메시지 처리 함수\n",
    "    title=\"맞춤형 여행 일정 계획 어시스턴트\", # 채팅 인터페이스의 제목\n",
    "    )\n",
    "\n",
    "# Gradio 인터페이스 실행\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}